package com.suneee.eas.common.uploader.s3;import com.amazonaws.services.s3.AmazonS3;import com.amazonaws.services.s3.model.*;import com.suneee.eas.common.bean.upload.ChunkUpload;import com.suneee.eas.common.bean.upload.UniqueUploadInfo;import com.suneee.eas.common.utils.ContextUtil;import com.suneee.eas.common.utils.StringUtil;import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.core.env.Environment;import java.io.File;import java.io.InputStream;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * @program: eas-parent * @description: 分段上传 * @author: liuhai * @create: 2018-10-22 10:17 **/public class MultiUploader implements MultiUploadHandler{    private static final Logger log = LogManager.getLogger(MultiUploader.class);    @Autowired    private AmazonS3 s3;    @Autowired    private Environment env;    private Map<String, Object> uploadMap = new HashMap<>();    /**     * 流上传     * @param bucket     * @param path     * @param inputStream     * @param chunkUpload     */    @Override    public CompleteMultipartUploadResult upload(String bucket, String path, InputStream inputStream, ChunkUpload chunkUpload) throws Exception{        int totalChunks = chunkUpload.getTotalChunks();        int currentChunk = chunkUpload.getChunkNumber();        long currentChunkSize = chunkUpload.getCurrentChunkSize();        String uniqueKey = chunkUpload.getIdentifier();        CompleteMultipartUploadResult result = null;        if(path.startsWith("/")){            path = path.substring(1, path.length());        }        try {            bucket = getBucket(bucket);            //获取上传文件唯一信息            UniqueUploadInfo uploadInfo = uploadMap.get(uniqueKey)==null?new UniqueUploadInfo():(UniqueUploadInfo)uploadMap.get(uniqueKey);            String uploadId = this.getUploadId(bucket, path, uploadInfo);            path = this.getPath(path, uploadInfo);            List<PartETag> eTags = this.getETagList(uploadInfo);            //上传            UploadPartRequest partRequest = this.initPartUpload(bucket, path, uploadId, inputStream, currentChunk, currentChunkSize);            UploadPartResult partResult = this.uploadPart(partRequest);            eTags.add(partResult.getPartETag());            uploadInfo.seteTagsList(eTags);            uploadMap.put(uniqueKey, uploadInfo);            //如果是最后一块，则完成上传            if(eTags.size() == totalChunks){                result = this.completeMultiUpload(bucket, path, uploadId, eTags);                uploadMap.remove(uploadInfo);            }        } catch (Exception e) {            log.error("上传失败："+e.getMessage(), e);            //删除缓存            uploadMap.remove(uniqueKey);        }        return result;    }    /**     * file对象上传     * @param bucket     * @param path     * @param file     * @param chunkUpload     */    @Override    public CompleteMultipartUploadResult upload(String bucket, String path, File file, ChunkUpload chunkUpload) throws Exception{        int totalChunks = chunkUpload.getTotalChunks();        int currentChunk = chunkUpload.getChunkNumber();        long currentChunkSize = chunkUpload.getCurrentChunkSize();        String uniqueKey = chunkUpload.getIdentifier();        CompleteMultipartUploadResult result = null;        if(path.startsWith("/")){            path = path.substring(1, path.length());        }        try {            bucket = getBucket(bucket);            //获取上传文件唯一信息            UniqueUploadInfo uploadInfo = uploadMap.get(uniqueKey)==null?new UniqueUploadInfo():(UniqueUploadInfo)uploadMap.get(uniqueKey);            String uploadId = this.getUploadId(bucket, path, uploadInfo);            path = this.getPath(path, uploadInfo);            List<PartETag> eTags = this.getETagList(uploadInfo);            //上传            UploadPartRequest partRequest = this.initPartUpload(bucket, path, uploadId, file, currentChunk, currentChunkSize);            UploadPartResult partResult = this.uploadPart(partRequest);            eTags.add(partResult.getPartETag());            uploadInfo.seteTagsList(eTags);            uploadMap.put(uniqueKey, uploadInfo);            //如果是最后一块，则完成上传            if(eTags.size() == totalChunks){                result = this.completeMultiUpload(bucket, path, uploadId, eTags);                uploadMap.remove(uploadInfo);            }        } catch (Exception e) {            //删除缓存            uploadMap.remove(uniqueKey);            e.printStackTrace();        }        return result;    }    /**     * 上传当前分块     * @param uploadPart     * @return     */    @Override    public UploadPartResult uploadPart(UploadPartRequest uploadPart) {        return s3.uploadPart(uploadPart);    }    /**     * 获取上传id     * @param bucketName     * @param keyName     * @param uniqueUploadInfo     * @return     */    @Override    public String getUploadId(String bucketName, String keyName, UniqueUploadInfo uniqueUploadInfo){        //如果没有则调用接口生成        if(StringUtil.isEmpty(uniqueUploadInfo.getUploadId())){            uniqueUploadInfo.setUploadId(getUploadId(bucketName, keyName));        }        return uniqueUploadInfo.getUploadId();    }    /**     * 获取路径     * @param keyName     * @param uniqueUploadInfo     * @return     */    @Override    public String getPath(String keyName, UniqueUploadInfo uniqueUploadInfo){        if(StringUtil.isEmpty(uniqueUploadInfo.getPath())){            uniqueUploadInfo.setPath(keyName);        }        return uniqueUploadInfo.getPath();    }    /**     * 获取eTags     * @param uniqueUploadInfo     * @return     */    @Override    public List<PartETag> getETagList(UniqueUploadInfo uniqueUploadInfo){        if(uniqueUploadInfo.geteTagsList().size() == 0){            uniqueUploadInfo.seteTagsList(new ArrayList<>());        }        return uniqueUploadInfo.geteTagsList();    }    /**     * 获取上传唯一标识id     * @param bucketName     * @param keyName     * @return     */    @Override    public String getUploadId(String bucketName, String keyName) {        //获取uploadId:一个文件上传到云存储的唯一标识        InitiateMultipartUploadRequest initRequest = new InitiateMultipartUploadRequest(bucketName, keyName);        InitiateMultipartUploadResult initResponse = s3.initiateMultipartUpload(initRequest);        return initResponse.getUploadId();    }    /**     * 完成单个文件上传     * @param bucketName     * @param keyName     * @param eTagList     * @return     */    @Override    public CompleteMultipartUploadResult completeMultiUpload(String bucketName, String keyName, String uploadId, List<PartETag> eTagList) {        CompleteMultipartUploadRequest comRequest = new CompleteMultipartUploadRequest(bucketName, keyName, uploadId, eTagList);        return s3.completeMultipartUpload(comRequest);    }    /**     * 创建分块上传对象     * @param bucketName     * @param keyName     * @param uploadId     * @param inputStream     * @param partNumber     * @param partSize     * @param file     * @param fileOffset     * @param isLastPart     * @param md5Digest     * @param objectMetadata     * @param sseCustomerKey     * @return     */    @Override    public UploadPartRequest initPartUpload(String bucketName, String keyName, String uploadId, InputStream inputStream,                                            int partNumber, long partSize, File file, long fileOffset,                                            boolean isLastPart, String md5Digest, ObjectMetadata objectMetadata,                                            SSECustomerKey sseCustomerKey) {        UploadPartRequest uploadRequest = new UploadPartRequest();        uploadRequest.setBucketName(bucketName);        uploadRequest.setKey(keyName);        uploadRequest.setUploadId(uploadId);        uploadRequest.setInputStream(inputStream);        uploadRequest.setPartNumber(partNumber);        uploadRequest.setPartSize(partSize);        uploadRequest.setFile(file);        uploadRequest.setFileOffset(fileOffset);        uploadRequest.setLastPart(isLastPart);        uploadRequest.setMd5Digest(md5Digest);        uploadRequest.setObjectMetadata(objectMetadata);        uploadRequest.setSSECustomerKey(sseCustomerKey);        return uploadRequest;    }    @Override    public UploadPartRequest initPartUpload(String bucketName, String keyName, String uploadId, InputStream inputStream, int partNumber, long partSize) {        return this.initPartUpload(bucketName, keyName, uploadId, inputStream, partNumber, partSize, 0);    }    @Override    public UploadPartRequest initPartUpload(String bucketName, String keyName, String uploadId, InputStream inputStream, int partNumber, long partSize, long fileOffset) {        return this.initPartUpload(bucketName, keyName, uploadId, inputStream, partNumber, partSize, null, fileOffset, false, null, null, null);    }    @Override    public UploadPartRequest initPartUpload(String bucketName, String keyName, String uploadId, File file, int partNumber, long partSize) {        return this.initPartUpload(bucketName, keyName, uploadId, file, partNumber, partSize, 0);    }    @Override    public UploadPartRequest initPartUpload(String bucketName, String keyName, String uploadId, File file, int partNumber, long partSize, long fileOffset) {        return this.initPartUpload(bucketName, keyName, uploadId, null, partNumber, partSize, file, fileOffset, false, null, null, null);    }    /**     * 获取桶     * @param bucketName     * @return     */    private String getBucket(String bucketName){        if(StringUtil.isNotEmpty(bucketName)){            return bucketName;        }        if (StringUtil.isEmpty(ContextUtil.getRuntimeEnv())){            return env.getProperty("uploader.s3.bucket","suneee");        }        return env.getProperty("uploader.minio.bucket."+ ContextUtil.getRuntimeEnv());    }}